{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spectroGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hegde95/GAN-for-speech-spectrogram/blob/master/src/spectroGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEw5XLatnfPb",
        "colab_type": "text"
      },
      "source": [
        "The CycleGAN code in this notebook is based on [this link](https://machinelearningmastery.com/cyclegan-tutorial-with-keras/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF_RGlK8eXKR",
        "colab_type": "text"
      },
      "source": [
        "# Complete Code in a cell\n",
        "\n",
        "Change line 34-37 according to your preference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-l2XPgydfbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import librosa\n",
        "import time\n",
        "from os import path\n",
        "import os\n",
        "import imageio\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "def mkdir(base, name):\n",
        "  path = os.path.join(base, name)\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "  return path\n",
        "\n",
        "# change the following 4 lines\n",
        "main_dir = \"/content/drive/My Drive/EE599/Project\"\n",
        "path_to_npz = \"/content/drive/My Drive/EE599/Project/npzs/happy2sad.npz\"\n",
        "domain_a = \"happy\"\n",
        "domain_b = \"sad\"\n",
        "\n",
        "path_to_logs = mkdir(main_dir,\"logs\")\n",
        "path_to_log = mkdir(path_to_logs,domain_a+'-'+domain_b+'_'+str(int(time.time())))\n",
        "\n",
        "# define the discriminator model\n",
        "def define_discriminator(image_shape):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# source image input\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\t# C64\n",
        "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C128\n",
        "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C256\n",
        "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C512\n",
        "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# second last output layer\n",
        "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# patch output\n",
        "\tpatch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\t# define model\n",
        "\tmodel = Model(in_image, patch_out)\n",
        "\t# compile model\n",
        "\tmodel.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
        "\tplot_model(model, to_file='discriminator_model.png', show_shapes=True, show_layer_names=True)\n",
        "\treturn model\n",
        "\n",
        "# generator a resnet block\n",
        "def resnet_block(n_filters, input_layer):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# first layer convolutional layer\n",
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# second convolutional layer\n",
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\t# concatenate merge channel-wise with input layer\n",
        "\tg = Concatenate()([g, input_layer])\n",
        "\treturn g\n",
        "\n",
        "# define the standalone generator model\n",
        "def define_generator(image_shape, n_resnet=6):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# image input\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\t# c7s1-64\n",
        "\tg = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# d128\n",
        "\tg = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# d256\n",
        "\tg = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# R256\n",
        "\tfor _ in range(n_resnet):\n",
        "\t\tg = resnet_block(256, g)\n",
        "\t# u128\n",
        "\tg = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# u64\n",
        "\tg = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# c7s1-3\n",
        "\tg = Conv2D(1, (7,7), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tout_image = Activation('tanh')(g)\n",
        "\t# define model\n",
        "\tmodel = Model(in_image, out_image)\n",
        "\t#plot_model(model, to_file='generator_model.png', show_shapes=True, show_layer_names=True)\n",
        "\treturn model\n",
        "\n",
        "# define a composite model for updating generators by adversarial and cycle loss\n",
        "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
        "\t# ensure the model we're updating is trainable\n",
        "\tg_model_1.trainable = True\n",
        "\t# mark discriminator as not trainable\n",
        "\td_model.trainable = False\n",
        "\t# mark other generator model as not trainable\n",
        "\tg_model_2.trainable = False\n",
        "\t# discriminator element\n",
        "\tinput_gen = Input(shape=image_shape)\n",
        "\tgen1_out = g_model_1(input_gen)\n",
        "\toutput_d = d_model(gen1_out)\n",
        "\t# identity element\n",
        "\tinput_id = Input(shape=image_shape)\n",
        "\toutput_id = g_model_1(input_id)\n",
        "\t# forward cycle\n",
        "\toutput_f = g_model_2(gen1_out)\n",
        "\t# backward cycle\n",
        "\tgen2_out = g_model_2(input_id)\n",
        "\toutput_b = g_model_1(gen2_out)\n",
        "\t# define model graph\n",
        "\tmodel = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
        "\t# define optimization algorithm configuration\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\t# compile model with weighting of least squares loss and L1 loss\n",
        "\tmodel.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n",
        "\t#\tplot_model(model, to_file='composite_model.png', show_shapes=True, show_layer_names=True)\n",
        "\treturn model\n",
        "\n",
        "# load and prepare training images\n",
        "def load_real_samples(filename):\n",
        "\t# load the dataset\n",
        "\tdata = np.load(filename)\n",
        "\t# unpack arrays\n",
        "\tX1, X2 = data['arr_0'], data['arr_1']\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tX1 = (X1 - 127.5) / 127.5\n",
        "\tX2 = (X2 - 127.5) / 127.5\n",
        "\treturn [X1, X2]\n",
        "\n",
        "# select a batch of random samples, returns images and target\n",
        "def generate_real_samples(dataset, n_samples, patch_shape):\n",
        "\t# choose random instances\n",
        "\tix = np.random.randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# generate a batch of images, returns images and targets\n",
        "def generate_fake_samples(g_model, dataset, patch_shape):\n",
        "\t# generate fake instance\n",
        "\tX = g_model.predict(dataset)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = np.zeros((len(X), patch_shape, patch_shape, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# save the generator models to file\n",
        "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
        "\tpath_to_step_folder = mkdir(path_to_log,str(step+1))\n",
        "\n",
        "\t# save the first generator model\n",
        "\tfilename1 = 'g_model_AtoB_%06d.h5' % (step+1)\n",
        "\tg_model_AtoB.save(path.join(path_to_step_folder,filename1))\n",
        "\t# save the second generator model\n",
        "\tfilename2 = 'g_model_BtoA_%06d.h5' % (step+1)\n",
        "\tg_model_BtoA.save(path.join(path_to_step_folder,filename2))\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))\n",
        " \n",
        "def make_test_folder(X_in, X_out, name, step, n_samples=5):\n",
        "\tpath_to_step_folder = mkdir(path_to_log,str(step+1))\n",
        "\tpath_to_step_folder_name = mkdir(path_to_step_folder,name)\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(2, n_samples, 1 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_in[i].reshape(260,260), cmap='gray')\n",
        "\t\timageio.imwrite(path.join(path_to_step_folder_name,str(i)+\"_real_\"+name.split('_')[0]+\".jpg\"), X_in[i].reshape(260,260))\n",
        "\t\tim = cv2.imread(path.join(path_to_step_folder_name,str(i)+\"_real_\"+name.split('_')[0]+\".jpg\"),-1)\n",
        "\t\tim = im[:257,:257]\n",
        "\t\tim = (im*80.0/255.0 ) -80.0\n",
        "\t\tim = librosa.db_to_amplitude(im)\n",
        "\t\ty2 = griffinlim(im,hop_length=256)\n",
        "\t\twrite(path.join(path_to_step_folder_name,str(i)+\"_real_\"+name.split('_')[0]+\".wav\"), 16000, y2*1.5)\n",
        "\t# plot translated image\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(2, n_samples, 1 + n_samples + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_out[i].reshape(260,260), cmap='gray')\n",
        "\t\timageio.imwrite(path.join(path_to_step_folder_name,str(i)+\"_generated_\"+name.split('_')[2]+\".jpg\"), X_out[i].reshape(260,260))\n",
        "\t\tim = cv2.imread(path.join(path_to_step_folder_name,str(i)+\"_generated_\"+name.split('_')[2]+\".jpg\"),-1)\n",
        "\t\tim = im[:257,:257]\n",
        "\t\tim = (im*80.0/255.0 ) -80.0\n",
        "\t\tim = librosa.db_to_amplitude(im)\n",
        "\t\ty2 = griffinlim(im,hop_length=256)\n",
        "\t\twrite(path.join(path_to_step_folder_name,str(i)+\"_generated_\"+name.split('_')[2]+\".wav\"), 16000, y2*1.5)\n",
        "\t# save plot to file\n",
        "\tfilename1 = '%s_generated_plot_%06d.png' % (name, (step+1))\n",
        "\tplt.savefig(path.join(path_to_step_folder,filename1),dpi = 300)\n",
        "\tplt.close()  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, trainX, name, n_samples=5):\n",
        "\t# select a sample of input images\n",
        "\tX_in, _ = generate_real_samples(trainX, n_samples, 0)\n",
        "\t# generate translated images\n",
        "\tX_out, _ = generate_fake_samples(g_model, X_in, 0)\n",
        "\t# scale all pixels from [-1,1] to [0,1]\n",
        "\tX_in = (X_in + 1) / 2.0\n",
        "\tX_out = (X_out + 1) / 2.0\n",
        "\tmake_test_folder(X_in, X_out, name, step, n_samples)\n",
        "\n",
        "# update image pool for fake images\n",
        "def update_image_pool(pool, images, max_size=50):\n",
        "\tselected = list()\n",
        "\tfor image in images:\n",
        "\t\tif len(pool) < max_size:\n",
        "\t\t\t# stock the pool\n",
        "\t\t\tpool.append(image)\n",
        "\t\t\tselected.append(image)\n",
        "\t\telif np.random.random() < 0.5:\n",
        "\t\t\t# use image, but don't add it to the pool\n",
        "\t\t\tselected.append(image)\n",
        "\t\telse:\n",
        "\t\t\t# replace an existing image and use replaced image\n",
        "\t\t\tix = np.random.randint(0, len(pool))\n",
        "\t\t\tselected.append(pool[ix])\n",
        "\t\t\tpool[ix] = image\n",
        "\treturn np.asarray(selected)\n",
        "def griffinlim(S, n_iter=32, hop_length=None, win_length=None, window='hann',\n",
        "\t\tcenter=True, dtype=np.float32, length=None, pad_mode='reflect',\n",
        "\t\tmomentum=0.99, init='random', random_state=None):\n",
        "\n",
        "    if random_state is None:\n",
        "        rng = np.random\n",
        "    elif isinstance(random_state, int):\n",
        "        rng = np.random.RandomState(seed=random_state)\n",
        "    elif isinstance(random_state, np.random.RandomState):\n",
        "        rng = random_state\n",
        "\n",
        "    if momentum > 1:\n",
        "        warnings.warn('Griffin-Lim with momentum={} > 1 can be unstable. '\n",
        "                      'Proceed with caution!'.format(momentum))\n",
        "    elif momentum < 0:\n",
        "        raise ParameterError('griffinlim() called with momentum={} < 0'.format(momentum))\n",
        "\n",
        "    # Infer n_fft from the spectrogram shape\n",
        "    n_fft = 2 * (S.shape[0] - 1)\n",
        "\n",
        "    # using complex64 will keep the result to minimal necessary precision\n",
        "    angles = np.empty(S.shape, dtype=np.complex64)\n",
        "    if init == 'random':\n",
        "        # randomly initialize the phase\n",
        "        angles[:] = np.exp(2j * np.pi * rng.rand(*S.shape))\n",
        "    elif init is None:\n",
        "        # Initialize an all ones complex matrix\n",
        "        angles[:] = 1.0\n",
        "    else:\n",
        "        raise ParameterError(\"init={} must either None or 'random'\".format(init))\n",
        "\n",
        "    # And initialize the previous iterate to 0\n",
        "    rebuilt = 0.\n",
        "\n",
        "    for _ in range(n_iter):\n",
        "        # Store the previous iterate\n",
        "        tprev = rebuilt\n",
        "\n",
        "        # Invert with our current estimate of the phases\n",
        "        inverse = librosa.istft(S * angles, hop_length=hop_length, win_length=win_length,\n",
        "                        window=window, center=center, dtype=dtype, length=length)\n",
        "\n",
        "        # Rebuild the spectrogram\n",
        "        rebuilt = librosa.stft(inverse, n_fft=n_fft, hop_length=hop_length,\n",
        "                       win_length=win_length, window=window, center=center,\n",
        "                       pad_mode=pad_mode)\n",
        "\n",
        "        # Update our phase estimates\n",
        "        angles[:] = rebuilt - (momentum / (1 + momentum)) * tprev\n",
        "        angles[:] /= np.abs(angles) + 1e-16\n",
        "\n",
        "    # Return the final phase estimates\n",
        "    return librosa.istft(S * angles, hop_length=hop_length, win_length=win_length,\n",
        "                 window=window, center=center, dtype=dtype, length=length)\n",
        "    \n",
        "\n",
        "# train cyclegan models\n",
        "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset):\n",
        "\t# define properties of the training run\n",
        "\tn_epochs, n_batch, = 500, 1\n",
        "\t# determine the output square shape of the discriminator\n",
        "\tn_patch = d_model_A.output_shape[1]\n",
        "\t# unpack dataset\n",
        "\ttrainA, trainB = dataset\n",
        "\t# prepare image pool for fakes\n",
        "\tpoolA, poolB = list(), list()\n",
        "\t# calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(len(trainA) / n_batch)\n",
        "\t# calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# select a batch of real samples\n",
        "\t\tX_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
        "\t\tX_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
        "\t\t# generate a batch of fake samples\n",
        "\t\tX_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
        "\t\tX_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
        "\t\t# update fakes from pool\n",
        "\t\tX_fakeA = update_image_pool(poolA, X_fakeA)\n",
        "\t\tX_fakeB = update_image_pool(poolB, X_fakeB)\n",
        "\t\t# update generator B->A via adversarial and cycle loss\n",
        "\t\tg_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
        "\t\t# update discriminator for A -> [real/fake]\n",
        "\t\tdA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
        "\t\tdA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
        "\t\t# update generator A->B via adversarial and cycle loss\n",
        "\t\tg_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
        "\t\t# update discriminator for B -> [real/fake]\n",
        "\t\tdB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
        "\t\tdB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
        "\t\t# summarize performance\n",
        "\t\tprint('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n",
        "\t\t# evaluate the model performance every so often\n",
        "\t\tif (i+1) % (bat_per_epo * 1) == 0:\n",
        "\t\t\t# plot A->B translation\n",
        "\t\t\tsummarize_performance(i, g_model_AtoB, trainA, domain_a+'_to_'+domain_b)\n",
        "\t\t\t# plot B->A translation\n",
        "\t\t\tsummarize_performance(i, g_model_BtoA, trainB, domain_b+'_to_'+domain_a)\n",
        "\t\tif (i+1) % (bat_per_epo * 5) == 0:\n",
        "\t\t\t# save the models\n",
        "\t\t\tsave_models(i, g_model_AtoB, g_model_BtoA)\n",
        "   \n",
        "# load image data\n",
        "dataset = load_real_samples(path_to_npz)\n",
        "#dataset[0] = dataset[0][:int(0.25*len(dataset[0]))]\n",
        "#dataset[1] = dataset[1][:int(0.20*len(dataset[1]))]\n",
        "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
        "# define input shape based on the loaded dataset\n",
        "image_shape = dataset[0].shape[1:]\n",
        "\n",
        "image_shape = (260,260,1)\n",
        "\n",
        "# generator: A -> B\n",
        "g_model_AtoB = define_generator(image_shape)\n",
        "# generator: B -> A\n",
        "g_model_BtoA = define_generator(image_shape)\n",
        "# discriminator: A -> [real/fake]\n",
        "d_model_A = define_discriminator(image_shape)\n",
        "# discriminator: B -> [real/fake]\n",
        "d_model_B = define_discriminator(image_shape)\n",
        "# composite: A -> B -> [real/fake, A]\n",
        "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
        "# composite: B -> A -> [real/fake, B]\n",
        "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n",
        "\n",
        "# train models\n",
        "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1oVe9pvidng",
        "colab_type": "text"
      },
      "source": [
        "# Commented code to make required npz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTWNGNBLLSTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!gdown https://drive.google.com/uc?id=1NzLsOqGvYanh2zM8jcb8_CTIjxFBJXA8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi0K6MFoMkZk",
        "colab_type": "code",
        "outputId": "4e28dbba-3571-4812-e36c-b9aa382e2317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# # #!unzip ravdess.zip\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyNeB8kL5Nru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import librosa\n",
        "# import random\n",
        "# import scipy.misc\n",
        "# import imageio\n",
        "\n",
        "# from PIL import Image\n",
        "\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# from os import path,listdir\n",
        "\n",
        "# path_to_audio = \"/content/drive/My Drive/EE599/Project/ravdes/audio\"\n",
        "# path_to_spec = \"/content/drive/My Drive/EE599/Project/ravdes/spec\"\n",
        "# emotions = [\"anger\",\"calm\",\"disgust\",\"fearful\",\"happy\",\"neutral\",\"sad\",\"surprised\"]\n",
        "\n",
        "# def get_audio(path_to_audio):\n",
        "#     y, sr = librosa.load(path_to_audio,sr=16000)\n",
        "#     return y,sr\n",
        "\n",
        "# def get_spectrogram(y):\n",
        "#     D = np.abs(librosa.stft(y,n_fft = 512,hop_length = 256))\n",
        "#     amp_max = np.amax(D)\n",
        "#     x = librosa.amplitude_to_db(D, ref=np.max)\n",
        "#     return x\n",
        "\n",
        "# def save_spec(array, name):\n",
        "#     imageio.imwrite(name, array)\n",
        "\n",
        "# for emotion in emotions:\n",
        "#     for file_name in listdir(path.join(path_to_audio,emotion)):\n",
        "#         file = path.join(*[path_to_audio,emotion,file_name])\n",
        "#         y,sr = get_audio(file)\n",
        "#         x = get_spectrogram(y)\n",
        "#         save_spec(x,path.join(*[path_to_spec,emotion,file_name[:-4]+'.jpg']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrDaai4mTXr5",
        "colab_type": "code",
        "outputId": "67f347b0-2bdc-446c-dbda-dcffdbe3c74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "# from os import path,listdir\n",
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# max_len = 260\n",
        "\n",
        "# # load and prepare training images\n",
        "# def getListOfFiles(dirName):\n",
        "#     # create a list of file and sub directories \n",
        "#     # names in the given directory \n",
        "#     listOfFile = os.listdir(dirName)\n",
        "#     allFiles = list()\n",
        "#     # Iterate over all the entries\n",
        "#     for entry in listOfFile:\n",
        "#         # Create full path\n",
        "#         fullPath = os.path.join(dirName, entry)\n",
        "#         # If entry is a directory then get the list of files in this directory \n",
        "#         if os.path.isdir(fullPath):\n",
        "#             allFiles = allFiles + getListOfFiles(fullPath)\n",
        "#         else:\n",
        "#             allFiles.append(fullPath)\n",
        "                \n",
        "#     return allFiles\n",
        "    \n",
        "# def make_npz(emo1,emo2):\n",
        "#   dirNameA = \"/content/drive/My Drive/EE599/Project/ravdes/spec/\"+emo1\n",
        "#   dirNameB = \"/content/drive/My Drive/EE599/Project/ravdes/spec/\"+emo2\n",
        "#   print(\"making {}\".format(emo1+'2'+emo2+'.npz'))\n",
        "#   #neutral\n",
        "#   trainA = []\n",
        "#   listA = getListOfFiles(dirNameA)\n",
        "#   listA.sort()\n",
        "#   for name in listA:\n",
        "#     img = cv2.imread(name,-1)\n",
        "#     img_f = np.zeros((260,260))\n",
        "#     y_len = img.shape[1]\n",
        "#     img = img[:,y_len//2-max_len//2:y_len//2+max_len//2]\n",
        "#     img_f[:257,:257] = img[:257,:257]\n",
        "#     trainA.append(img_f)\n",
        "#   trainA = np.array(trainA)\n",
        "\n",
        "#   trainB = []\n",
        "#   listB = getListOfFiles(dirNameB)\n",
        "#   listB.sort()\n",
        "#   for name in listB:\n",
        "#     img = cv2.imread(name,-1)\n",
        "#     y_len = img.shape[1]\n",
        "#     img = img[:,y_len//2-max_len//2:y_len//2+max_len//2]\n",
        "#     img_f = np.zeros((260,260))\n",
        "#     img_f[:257,:257] = img[:257,:257]\n",
        "#     trainB.append(img_f)\n",
        "#   trainB = np.array(trainB)\n",
        "#   filename = '/content/drive/My Drive/EE599/Project/npzs2/'+emo1+'2'+emo2+'.npz'\n",
        "#   np.savez_compressed(filename, trainA, trainB)\n",
        "\n",
        "# emotions = [\"calm\",\"anger\",\"disgust\",\"fearful\",\"happy\",\"neutral\",\"sad\",\"surprised\"]\n",
        "# for i in range(len(emotions)):\n",
        "#     for j in range(i+1,len(emotions)):\n",
        "#         make_npz(emotions[i],emotions[j])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "making calm2anger.npz\n",
            "making calm2disgust.npz\n",
            "making calm2fearful.npz\n",
            "making calm2happy.npz\n",
            "making calm2neutral.npz\n",
            "making calm2sad.npz\n",
            "making calm2surprised.npz\n",
            "making anger2disgust.npz\n",
            "making anger2fearful.npz\n",
            "making anger2happy.npz\n",
            "making anger2neutral.npz\n",
            "making anger2sad.npz\n",
            "making anger2surprised.npz\n",
            "making disgust2fearful.npz\n",
            "making disgust2happy.npz\n",
            "making disgust2neutral.npz\n",
            "making disgust2sad.npz\n",
            "making disgust2surprised.npz\n",
            "making fearful2happy.npz\n",
            "making fearful2neutral.npz\n",
            "making fearful2sad.npz\n",
            "making fearful2surprised.npz\n",
            "making happy2neutral.npz\n",
            "making happy2sad.npz\n",
            "making happy2surprised.npz\n",
            "making neutral2sad.npz\n",
            "making neutral2surprised.npz\n",
            "making sad2surprised.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq9H74s4iOdJ",
        "colab_type": "text"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEsfSGFw-Xfv",
        "colab_type": "code",
        "outputId": "c0c29551-6d0c-433a-b5dc-cc46f91eade5",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "#@title Mount Drive - Please authourise if needed\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLw4TvgXMuba",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Imports\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import librosa\n",
        "import time\n",
        "from os import path\n",
        "import os\n",
        "import imageio\n",
        "from scipy.io.wavfile import write"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YehOpTiTArAD",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Data and Log Locations\n",
        "\n",
        "import time\n",
        "def mkdir(base, name):\n",
        "  path = os.path.join(base, name)\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "  return path\n",
        "\n",
        "#@markdown Give domain names (ensure the name of the npz is domain_a2domain_b).\n",
        "domain_a = \"happy\" #@param {type:\"string\"}\n",
        "domain_b = \"sad\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Give complete drive path to the npz file here.\n",
        "path_to_npz = \"/content/drive/My Drive/EE599/Project/npzs/happy2sad.npz\" #@param {type:\"string\"}\n",
        "\n",
        " \n",
        "#@markdown Give complete drive path to the npz file here.\n",
        "main_dir = \"/content/drive/My Drive/EE599/Project\" #@param {type:\"string\"}\n",
        "path_to_logs = mkdir(main_dir,\"logs\")\n",
        "path_to_log = mkdir(path_to_logs,domain_a+'-'+domain_b+'_'+str(int(time.time())))\n",
        "\n",
        "assert path_to_npz.split(\"/\")[-1][:-4] == domain_a+\"2\"+domain_b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrqLHI7sgY1U",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxwfdHPRNDfj",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title GAN Util methods\n",
        "# define the discriminator model\n",
        "def define_discriminator(image_shape):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# source image input\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\t# C64\n",
        "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C128\n",
        "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C256\n",
        "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C512\n",
        "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# second last output layer\n",
        "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# patch output\n",
        "\tpatch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\t# define model\n",
        "\tmodel = Model(in_image, patch_out)\n",
        "\t# compile model\n",
        "\tmodel.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
        "\tplot_model(model, to_file='discriminator_model.png', show_shapes=True, show_layer_names=True)\n",
        "\treturn model\n",
        "\n",
        "# generator a resnet block\n",
        "def resnet_block(n_filters, input_layer):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# first layer convolutional layer\n",
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# second convolutional layer\n",
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\t# concatenate merge channel-wise with input layer\n",
        "\tg = Concatenate()([g, input_layer])\n",
        "\treturn g\n",
        "\n",
        "# define the standalone generator model\n",
        "def define_generator(image_shape, n_resnet=6):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# image input\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\t# c7s1-64\n",
        "\tg = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# d128\n",
        "\tg = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# d256\n",
        "\tg = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# R256\n",
        "\tfor _ in range(n_resnet):\n",
        "\t\tg = resnet_block(256, g)\n",
        "\t# u128\n",
        "\tg = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# u64\n",
        "\tg = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# c7s1-3\n",
        "\tg = Conv2D(1, (7,7), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tout_image = Activation('tanh')(g)\n",
        "\t# define model\n",
        "\tmodel = Model(in_image, out_image)\n",
        "\t#plot_model(model, to_file='generator_model.png', show_shapes=True, show_layer_names=True)\n",
        "\treturn model\n",
        "\n",
        "# define a composite model for updating generators by adversarial and cycle loss\n",
        "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
        "\t# ensure the model we're updating is trainable\n",
        "\tg_model_1.trainable = True\n",
        "\t# mark discriminator as not trainable\n",
        "\td_model.trainable = False\n",
        "\t# mark other generator model as not trainable\n",
        "\tg_model_2.trainable = False\n",
        "\t# discriminator element\n",
        "\tinput_gen = Input(shape=image_shape)\n",
        "\tgen1_out = g_model_1(input_gen)\n",
        "\toutput_d = d_model(gen1_out)\n",
        "\t# identity element\n",
        "\tinput_id = Input(shape=image_shape)\n",
        "\toutput_id = g_model_1(input_id)\n",
        "\t# forward cycle\n",
        "\toutput_f = g_model_2(gen1_out)\n",
        "\t# backward cycle\n",
        "\tgen2_out = g_model_2(input_id)\n",
        "\toutput_b = g_model_1(gen2_out)\n",
        "\t# define model graph\n",
        "\tmodel = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
        "\t# define optimization algorithm configuration\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\t# compile model with weighting of least squares loss and L1 loss\n",
        "\tmodel.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n",
        "\t#\tplot_model(model, to_file='composite_model.png', show_shapes=True, show_layer_names=True)\n",
        "\treturn model\n",
        "\n",
        "# load and prepare training images\n",
        "def load_real_samples(filename):\n",
        "\t# load the dataset\n",
        "\tdata = np.load(filename)\n",
        "\t# unpack arrays\n",
        "\tX1, X2 = data['arr_0'], data['arr_1']\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tX1 = (X1 - 127.5) / 127.5\n",
        "\tX2 = (X2 - 127.5) / 127.5\n",
        "\treturn [X1, X2]\n",
        "\n",
        "# select a batch of random samples, returns images and target\n",
        "def generate_real_samples(dataset, n_samples, patch_shape):\n",
        "\t# choose random instances\n",
        "\tix = np.random.randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# generate a batch of images, returns images and targets\n",
        "def generate_fake_samples(g_model, dataset, patch_shape):\n",
        "\t# generate fake instance\n",
        "\tX = g_model.predict(dataset)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = np.zeros((len(X), patch_shape, patch_shape, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# save the generator models to file\n",
        "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
        "\tpath_to_step_folder = mkdir(path_to_log,str(step+1))\n",
        "\n",
        "\t# save the first generator model\n",
        "\tfilename1 = 'g_model_AtoB_%06d.h5' % (step+1)\n",
        "\tg_model_AtoB.save(path.join(path_to_step_folder,filename1))\n",
        "\t# save the second generator model\n",
        "\tfilename2 = 'g_model_BtoA_%06d.h5' % (step+1)\n",
        "\tg_model_BtoA.save(path.join(path_to_step_folder,filename2))\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))\n",
        " \n",
        "def make_test_folder(X_in, X_out, name, step, n_samples=5):\n",
        "\tpath_to_step_folder = mkdir(path_to_log,str(step+1))\n",
        "\tpath_to_step_folder_name = mkdir(path_to_step_folder,name)\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(2, n_samples, 1 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_in[i].reshape(260,260), cmap='gray')\n",
        "\t\timageio.imwrite(path.join(path_to_step_folder_name,str(i)+\"_real_\"+name.split('_')[0]+\".jpg\"), X_in[i].reshape(260,260))\n",
        "\t\tim = cv2.imread(path.join(path_to_step_folder_name,str(i)+\"_real_\"+name.split('_')[0]+\".jpg\"),-1)\n",
        "\t\tim = im[:257,:257]\n",
        "\t\tim = (im*80.0/255.0 ) -80.0\n",
        "\t\tim = librosa.db_to_amplitude(im)\n",
        "\t\ty2 = griffinlim(im,hop_length=256)\n",
        "\t\twrite(path.join(path_to_step_folder_name,str(i)+\"_real_\"+name.split('_')[0]+\".wav\"), 16000, y2*1.5)\n",
        "\t# plot translated image\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(2, n_samples, 1 + n_samples + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_out[i].reshape(260,260), cmap='gray')\n",
        "\t\timageio.imwrite(path.join(path_to_step_folder_name,str(i)+\"_generated_\"+name.split('_')[2]+\".jpg\"), X_out[i].reshape(260,260))\n",
        "\t\tim = cv2.imread(path.join(path_to_step_folder_name,str(i)+\"_generated_\"+name.split('_')[2]+\".jpg\"),-1)\n",
        "\t\tim = im[:257,:257]\n",
        "\t\tim = (im*80.0/255.0 ) -80.0\n",
        "\t\tim = librosa.db_to_amplitude(im)\n",
        "\t\ty2 = griffinlim(im,hop_length=256)\n",
        "\t\twrite(path.join(path_to_step_folder_name,str(i)+\"_generated_\"+name.split('_')[2]+\".wav\"), 16000, y2*1.5)\n",
        "\t# save plot to file\n",
        "\tfilename1 = '%s_generated_plot_%06d.png' % (name, (step+1))\n",
        "\tplt.savefig(path.join(path_to_step_folder,filename1),dpi = 300)\n",
        "\tplt.close()  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, trainX, name, n_samples=5):\n",
        "\t# select a sample of input images\n",
        "\tX_in, _ = generate_real_samples(trainX, n_samples, 0)\n",
        "\t# generate translated images\n",
        "\tX_out, _ = generate_fake_samples(g_model, X_in, 0)\n",
        "\t# scale all pixels from [-1,1] to [0,1]\n",
        "\tX_in = (X_in + 1) / 2.0\n",
        "\tX_out = (X_out + 1) / 2.0\n",
        "\tmake_test_folder(X_in, X_out, name, step, n_samples)\n",
        "\n",
        "# update image pool for fake images\n",
        "def update_image_pool(pool, images, max_size=50):\n",
        "\tselected = list()\n",
        "\tfor image in images:\n",
        "\t\tif len(pool) < max_size:\n",
        "\t\t\t# stock the pool\n",
        "\t\t\tpool.append(image)\n",
        "\t\t\tselected.append(image)\n",
        "\t\telif np.random.random() < 0.5:\n",
        "\t\t\t# use image, but don't add it to the pool\n",
        "\t\t\tselected.append(image)\n",
        "\t\telse:\n",
        "\t\t\t# replace an existing image and use replaced image\n",
        "\t\t\tix = np.random.randint(0, len(pool))\n",
        "\t\t\tselected.append(pool[ix])\n",
        "\t\t\tpool[ix] = image\n",
        "\treturn np.asarray(selected)\n",
        "def griffinlim(S, n_iter=32, hop_length=None, win_length=None, window='hann',\n",
        "\t\tcenter=True, dtype=np.float32, length=None, pad_mode='reflect',\n",
        "\t\tmomentum=0.99, init='random', random_state=None):\n",
        "\n",
        "    if random_state is None:\n",
        "        rng = np.random\n",
        "    elif isinstance(random_state, int):\n",
        "        rng = np.random.RandomState(seed=random_state)\n",
        "    elif isinstance(random_state, np.random.RandomState):\n",
        "        rng = random_state\n",
        "\n",
        "    if momentum > 1:\n",
        "        warnings.warn('Griffin-Lim with momentum={} > 1 can be unstable. '\n",
        "                      'Proceed with caution!'.format(momentum))\n",
        "    elif momentum < 0:\n",
        "        raise ParameterError('griffinlim() called with momentum={} < 0'.format(momentum))\n",
        "\n",
        "    # Infer n_fft from the spectrogram shape\n",
        "    n_fft = 2 * (S.shape[0] - 1)\n",
        "\n",
        "    # using complex64 will keep the result to minimal necessary precision\n",
        "    angles = np.empty(S.shape, dtype=np.complex64)\n",
        "    if init == 'random':\n",
        "        # randomly initialize the phase\n",
        "        angles[:] = np.exp(2j * np.pi * rng.rand(*S.shape))\n",
        "    elif init is None:\n",
        "        # Initialize an all ones complex matrix\n",
        "        angles[:] = 1.0\n",
        "    else:\n",
        "        raise ParameterError(\"init={} must either None or 'random'\".format(init))\n",
        "\n",
        "    # And initialize the previous iterate to 0\n",
        "    rebuilt = 0.\n",
        "\n",
        "    for _ in range(n_iter):\n",
        "        # Store the previous iterate\n",
        "        tprev = rebuilt\n",
        "\n",
        "        # Invert with our current estimate of the phases\n",
        "        inverse = librosa.istft(S * angles, hop_length=hop_length, win_length=win_length,\n",
        "                        window=window, center=center, dtype=dtype, length=length)\n",
        "\n",
        "        # Rebuild the spectrogram\n",
        "        rebuilt = librosa.stft(inverse, n_fft=n_fft, hop_length=hop_length,\n",
        "                       win_length=win_length, window=window, center=center,\n",
        "                       pad_mode=pad_mode)\n",
        "\n",
        "        # Update our phase estimates\n",
        "        angles[:] = rebuilt - (momentum / (1 + momentum)) * tprev\n",
        "        angles[:] /= np.abs(angles) + 1e-16\n",
        "\n",
        "    # Return the final phase estimates\n",
        "    return librosa.istft(S * angles, hop_length=hop_length, win_length=win_length,\n",
        "                 window=window, center=center, dtype=dtype, length=length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VvUXv1lNntM",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title GAN train method\n",
        "# train cyclegan models\n",
        "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset):\n",
        "\t# define properties of the training run\n",
        "\tn_epochs, n_batch, = 500, 1\n",
        "\t# determine the output square shape of the discriminator\n",
        "\tn_patch = d_model_A.output_shape[1]\n",
        "\t# unpack dataset\n",
        "\ttrainA, trainB = dataset\n",
        "\t# prepare image pool for fakes\n",
        "\tpoolA, poolB = list(), list()\n",
        "\t# calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(len(trainA) / n_batch)\n",
        "\t# calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# select a batch of real samples\n",
        "\t\tX_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
        "\t\tX_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
        "\t\t# generate a batch of fake samples\n",
        "\t\tX_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
        "\t\tX_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
        "\t\t# update fakes from pool\n",
        "\t\tX_fakeA = update_image_pool(poolA, X_fakeA)\n",
        "\t\tX_fakeB = update_image_pool(poolB, X_fakeB)\n",
        "\t\t# update generator B->A via adversarial and cycle loss\n",
        "\t\tg_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
        "\t\t# update discriminator for A -> [real/fake]\n",
        "\t\tdA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
        "\t\tdA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
        "\t\t# update generator A->B via adversarial and cycle loss\n",
        "\t\tg_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
        "\t\t# update discriminator for B -> [real/fake]\n",
        "\t\tdB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
        "\t\tdB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
        "\t\t# summarize performance\n",
        "\t\tprint('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n",
        "\t\t# evaluate the model performance every so often\n",
        "\t\tif (i+1) % (bat_per_epo * 1) == 0:\n",
        "\t\t\t# plot A->B translation\n",
        "\t\t\tsummarize_performance(i, g_model_AtoB, trainA, domain_a+'_to_'+domain_b)\n",
        "\t\t\t# plot B->A translation\n",
        "\t\t\tsummarize_performance(i, g_model_BtoA, trainB, domain_b+'_to_'+domain_a)\n",
        "\t\tif (i+1) % (bat_per_epo * 5) == 0:\n",
        "\t\t\t# save the models\n",
        "\t\t\tsave_models(i, g_model_AtoB, g_model_BtoA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjk9UBP3NvtF",
        "colab_type": "code",
        "outputId": "aae6a1cc-df39-43af-b7a9-4fede3b5763c",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Load the dataset\n",
        "# load image data\n",
        "dataset = load_real_samples(path_to_npz)\n",
        "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
        "# define input shape based on the loaded dataset\n",
        "# image_shape = dataset[0].shape[1:]\n",
        "image_shape = (260,260,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded (202, 260, 260) (196, 260, 260)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF6eIIkgkKaq",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Initialize Cycle GAN\n",
        "# generator: A -> B\n",
        "g_model_AtoB = define_generator(image_shape)\n",
        "# generator: B -> A\n",
        "g_model_BtoA = define_generator(image_shape)\n",
        "# discriminator: A -> [real/fake]\n",
        "d_model_A = define_discriminator(image_shape)\n",
        "# discriminator: B -> [real/fake]\n",
        "d_model_B = define_discriminator(image_shape)\n",
        "# composite: A -> B -> [real/fake, A]\n",
        "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
        "# composite: B -> A -> [real/fake, B]\n",
        "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8mlQqpyc5Sk",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Train the GAN\n",
        "# train models\n",
        "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP9YBguCl-oX",
        "colab_type": "text"
      },
      "source": [
        "# Fin"
      ]
    }
  ]
}